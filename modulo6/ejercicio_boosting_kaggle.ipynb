{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27527e85",
   "metadata": {},
   "source": [
    "\n",
    "# Ejercicio: Gradient Boosting con datos reales de Kaggle (House Prices)\n",
    "\n",
    "**Objetivo:** completar un flujo de ML con **Gradient Boosting** para predecir `SalePrice` usando el dataset **House Prices** de Kaggle.\n",
    "\n",
    "---\n",
    "\n",
    "## ¿Cómo instalar y usar Jupyter?\n",
    "\n",
    "### 1) Crear entorno virtual (opcional pero recomendado)\n",
    "```bash\n",
    "# macOS / Linux\n",
    "python3 -m venv myenv\n",
    "source myenv/bin/activate\n",
    "\n",
    "# Windows (PowerShell)\n",
    "py -m venv myenv\n",
    "myenv\\Scripts\\Activate.ps1\n",
    "```\n",
    "\n",
    "### 2) Instalar dependencias mínimas\n",
    "```bash\n",
    "pip install --upgrade pip\n",
    "pip install jupyter pandas numpy matplotlib scikit-learn\n",
    "```\n",
    "\n",
    "### 3) Abrir Jupyter\n",
    "```bash\n",
    "# Opción A: Jupyter Notebook\n",
    "jupyter notebook\n",
    "\n",
    "# Opción B: JupyterLab\n",
    "pip install jupyterlab\n",
    "jupyter lab\n",
    "```\n",
    "Jupyter abrirá una ventana en tu navegador. Crea/abre este notebook y ejecuta las celdas con **Shift+Enter**.\n",
    "\n",
    "---\n",
    "\n",
    "## ¿Cómo obtener el dataset de Kaggle?\n",
    "\n",
    "### Opción 1: Descarga manual\n",
    "1. Ve a la competición: *House Prices - Advanced Regression Techniques*.\n",
    "2. Descarga `train.csv` y guárdalo en una carpeta de tu proyecto, por ejemplo: `data/train.csv`.\n",
    "\n",
    "### Opción 2: Kaggle API (requiere configurar credenciales)\n",
    "```bash\n",
    "pip install kaggle\n",
    "# Coloca tu kaggle.json en ~/.kaggle/kaggle.json (Linux/macOS) o C:\\Users\\<USER>\\.kaggle\\kaggle.json (Windows)\n",
    "kaggle competitions download -c house-prices-advanced-regression-techniques\n",
    "unzip house-prices-advanced-regression-techniques.zip -d data\n",
    "```\n",
    "> Para este ejercicio bastará con **`train.csv`**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d7f799",
   "metadata": {},
   "source": [
    "## 1) Importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cc321c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# IMPORTA AQUÍ LAS LIBRERÍAS NECESARIAS\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "\n",
    "# IMPORTA AQUÍ LAS LIBRERÍAS NECESARIAS\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "# En versiones recientes usa root_mean_squared_error (si no, haremos un fallback manual)\n",
    "try:\n",
    "    from sklearn.metrics import root_mean_squared_error\n",
    "    _HAS_RMSE = True\n",
    "except Exception:\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    _HAS_RMSE = False\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "print(\"Librerías importadas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633f74f3",
   "metadata": {},
   "source": [
    "## 2) Cargar datos de Kaggle (`train.csv`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb11b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# AJUSTA ESTA RUTA A DONDE GUARDASTE train.csv\n",
    "DATA_PATH = \"data/train.csv\"  # <-- cambia si es necesario\n",
    "\n",
    "assert os.path.exists(DATA_PATH), f\"No se encontró {DATA_PATH}. Ajusta la ruta.\"\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47ceee6",
   "metadata": {},
   "source": [
    "## 3) Exploración inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43d31d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dimensiones, tipos y nulos\n",
    "display(df.info())\n",
    "display(df.isna().sum().sort_values(ascending=False).head(20))\n",
    "df.describe(include='all').T.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1563e73",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Seleccionar variables y preprocesar (versión simple)\n",
    "\n",
    "Para comenzar, usa un **subconjunto de variables numéricas** (puedes modificarlas):\n",
    "- `OverallQual`, `GrLivArea`, `GarageCars`, `YearBuilt`\n",
    "\n",
    "Variable objetivo: **`SalePrice`**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5ee366",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features_numeric = [\"OverallQual\", \"GrLivArea\", \"GarageCars\", \"YearBuilt\"]\n",
    "target = \"SalePrice\"\n",
    "\n",
    "# Filtrar filas completas en esas columnas\n",
    "data = df[features_numeric + [target]].dropna().copy()\n",
    "\n",
    "X = data[features_numeric]\n",
    "y = data[target]\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4113771",
   "metadata": {},
   "source": [
    "## 5) Dividir en entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c3e05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=RANDOM_STATE\n",
    ")\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b418087f",
   "metadata": {},
   "source": [
    "## 6) Crear y entrenar Gradient Boosting Regressor (básico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b9c6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gbr = GradientBoostingRegressor(\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=3,\n",
    "    subsample=0.9\n",
    ")\n",
    "gbr.fit(X_train, y_train)\n",
    "print(\"Modelo entrenado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091b1df9",
   "metadata": {},
   "source": [
    "## 7) Evaluar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe8b14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = gbr.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "if _HAS_RMSE:\n",
    "    rmse = root_mean_squared_error(y_test, y_pred)\n",
    "else:\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    import numpy as np\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MAE : {mae:0.4f}\")\n",
    "print(f\"RMSE: {rmse:0.4f}\")\n",
    "print(f\"R²  : {r2:0.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefb6278",
   "metadata": {},
   "source": [
    "## 8) Visualizar predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c633699",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# a) Dispersión y_real vs y_pred\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(y_test, y_pred, s=18, alpha=0.8)\n",
    "min_v = min(y_test.min(), y_pred.min())\n",
    "max_v = max(y_test.max(), y_pred.max())\n",
    "plt.plot([min_v, max_v], [min_v, max_v], linestyle=\"--\")\n",
    "plt.title(\"y_real vs y_pred (TEST)\")\n",
    "plt.xlabel(\"y_real\"); plt.ylabel(\"y_pred\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# b) Importancia de variables\n",
    "importances = pd.Series(gbr.feature_importances_, index=features_numeric).sort_values(ascending=True)\n",
    "plt.figure(figsize=(6,4))\n",
    "importances.plot(kind=\"barh\")\n",
    "plt.title(\"Importancia de variables (GBR)\")\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17af156",
   "metadata": {},
   "source": [
    "## 9) Mejorar el modelo (GridSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ad8672",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [200, 400, 600],\n",
    "    \"learning_rate\": [0.03, 0.06, 0.1],\n",
    "    \"max_depth\": [2, 3, 4],\n",
    "    \"subsample\": [0.8, 1.0]\n",
    "}\n",
    "\n",
    "gbr_base = GradientBoostingRegressor(random_state=RANDOM_STATE)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=gbr_base,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Mejores hiperparámetros:\", grid.best_params_)\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "if _HAS_RMSE:\n",
    "    rmse_best = root_mean_squared_error(y_test, y_pred_best)\n",
    "else:\n",
    "    rmse_best = np.sqrt(mean_squared_error(y_test, y_pred_best))\n",
    "r2_best = r2_score(y_test, y_pred_best)\n",
    "\n",
    "print(f\"RMSE base -> mejorado: {rmse:0.4f} -> {rmse_best:0.4f}\")\n",
    "print(f\"R²   base -> mejorado: {r2:0.4f} -> {r2_best:0.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53db349d",
   "metadata": {},
   "source": [
    "\n",
    "## 10) (Opcional) Pipeline con variables categóricas\n",
    "\n",
    "- Elige algunas columnas categóricas (p. ej., `Neighborhood`, `KitchenQual`, etc.).\n",
    "- Usa `OneHotEncoder` + `ColumnTransformer` y entrena un **Pipeline** con `GradientBoostingRegressor`.\n",
    "- Compara métricas con la versión numérica simple.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3788d410",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# EJEMPLO DE PLANTILLA (completa tú con columnas reales si quieres probar)\n",
    "\n",
    "# cols_num = [\"OverallQual\", \"GrLivArea\", \"GarageCars\", \"YearBuilt\"]\n",
    "# cols_cat = [\"Neighborhood\", \"KitchenQual\"]\n",
    "# used_cols = cols_num + cols_cat + [target]\n",
    "\n",
    "# data2 = df[used_cols].dropna().copy()\n",
    "# X2 = data2[cols_num + cols_cat]\n",
    "# y2 = data2[target]\n",
    "\n",
    "# pre = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         (\"num\", \"passthrough\", cols_num),\n",
    "#         (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cols_cat)\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# pipe = Pipeline([\n",
    "#     (\"prep\", pre),\n",
    "#     (\"model\", GradientBoostingRegressor(random_state=RANDOM_STATE))\n",
    "# ])\n",
    "\n",
    "# X2_train, X2_test, y2_train, y2_test = train_test_split(\n",
    "#     X2, y2, test_size=0.25, random_state=RANDOM_STATE\n",
    "# )\n",
    "# pipe.fit(X2_train, y2_train)\n",
    "# y2_pred = pipe.predict(X2_test)\n",
    "\n",
    "# if _HAS_RMSE:\n",
    "#     rmse2 = root_mean_squared_error(y2_test, y2_pred)\n",
    "# else:\n",
    "#     rmse2 = np.sqrt(mean_squared_error(y2_test, y2_pred))\n",
    "# r2_2 = r2_score(y2_test, y2_pred)\n",
    "\n",
    "# print(f\"RMSE (pipeline categóricas): {rmse2:0.4f}\")\n",
    "# print(f\"R²   (pipeline categóricas): {r2_2:0.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
